Metadata-Version: 2.1
Name: yolosegment2labelme
Version: 0.0.2
Summary: A small example package
Home-page: https://github.com/Abonia1/yolosegment2labelme
Download-URL: https://github.com/Abonia1/yolosegment2labelme/archive/refs/tags/v2.0.zip
Author: Abonia Sojasingarayar
Author-email: Abonia Sojasingarayar <aboniaa@gmail.com>
Project-URL: Homepage, https://github.com/Abonia1/yolosegment2labelme
Project-URL: Issues, https://github.com/Abonia1/yolosegment2labelme/issues
Keywords: python,yolo,segmentation,json,labelme,anylabeling
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: numpy
Requires-Dist: opencv-python
Requires-Dist: pillow
Requires-Dist: ultralytics

# yolosegment2labelme

**yolosegment2labelme** is a Python package that allows you to convert YOLO segmentation prediction results to LabelMe JSON format. This tool facilitates the annotation process by generating JSON files that are compatible with LabelMe and other labeling annotation tools.

## Features

- Convert YOLO segmentation prediction results to LabelMe JSON format.
- Compatible with various YOLO models.
- Easy-to-use command-line interface.
- Supports batch processing of images.
- Customizable confidence threshold for predictions.
- Highly customizable and extensible for specific use cases.

## Installation

You can install **yolosegment2labelme** via pip:

```bash
pip install yolosegment2labelme
```

## Usage

After installation, you can use the `yolosegment2labelme` command-line interface to convert YOLO segmentation prediction results to LabelMe JSON format. Here's a basic example:

```bash
yolosegment2labelme --images /path/to/images
```

or with custom yolo segmentation model

```bash
yolosegment2labelme --model yolov8n-seg.pt --images /path/to/images --conf 0.3
```

This command will process the images located in the specified directory (`/path/to/images`), using the YOLO model weights file `yolov8n-seg.pt`, and generate LabelMe JSON files with a confidence threshold of 0.3.

For more options and advanced usage, refer to the [documentation](https://github.com/Abonia1/yolosegment2labelme).

## Sample Images
The table below displays sample images along with their corresponding annotations generated using yolosegment2labelme:

## Sample Images

| Sample Image 1                                      | Sample Image 2                                      |
|-----------------------------------------------------|-----------------------------------------------------|
| ![Sample Image 1](images/labelme_test/sample1.png)      | ![Sample Image 2](images/labelme_test/sample2.png)      |
| Sample Annotation for Image 1                      | Sample Annotation for Image 2                      |

| Sample Image 3                                      | Sample Image 4                                      |
|-----------------------------------------------------|-----------------------------------------------------|
| ![Sample Image 3](images/labelme_test/sample3.png)      | ![Sample Image 4](images/labelme_test/sample4.png)      |
| Sample Annotation for Image 3                      | Sample Annotation for Image 4                      |


## Documentation

The documentation for **yolosegment2labelme** can be found on GitHub: [yolosegment2labelme Documentation](https://github.com/Abonia1/yolosegment2labelme)

## Contributing

Contributions are welcome! If you'd like to contribute to **yolosegment2labelme**, please check out the [Contribution Guidelines](CONTRIBUTING.md).

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Authors

- Abonia Sojasingarayar - [GitHub](https://github.com/Abonia1)

## Support

If you encounter any issues or have questions about **yolosegment2labelme**, please feel free to open an issue on GitHub: [yolosegment2labelme Issues](https://github.com/Abonia1/yolosegment2labelme/issues)
